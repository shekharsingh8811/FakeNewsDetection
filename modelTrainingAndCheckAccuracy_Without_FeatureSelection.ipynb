{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the libraries and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "## For Feature Selection\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "## For Splitting data into Test and Train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## For Classfication Models\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## For Accuracy\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please update the file name as per chosen dataset.\n",
    "all_Features = pd.read_csv('All_Features_No_Norm.csv', sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10949, 186)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>urlType</th>\n",
       "      <th>L_WC</th>\n",
       "      <th>L_Analytic</th>\n",
       "      <th>L_Clout</th>\n",
       "      <th>L_Authentic</th>\n",
       "      <th>L_Tone</th>\n",
       "      <th>L_WPS</th>\n",
       "      <th>L_Sixltr</th>\n",
       "      <th>L_Dic</th>\n",
       "      <th>L_function</th>\n",
       "      <th>L_pronoun</th>\n",
       "      <th>L_ppron</th>\n",
       "      <th>L_i</th>\n",
       "      <th>L_we</th>\n",
       "      <th>L_you</th>\n",
       "      <th>L_shehe</th>\n",
       "      <th>L_they</th>\n",
       "      <th>L_ipron</th>\n",
       "      <th>L_article</th>\n",
       "      <th>L_prep</th>\n",
       "      <th>L_auxverb</th>\n",
       "      <th>L_adverb</th>\n",
       "      <th>L_conj</th>\n",
       "      <th>L_negate</th>\n",
       "      <th>L_verb</th>\n",
       "      <th>L_adj</th>\n",
       "      <th>L_compare</th>\n",
       "      <th>L_interrog</th>\n",
       "      <th>L_number</th>\n",
       "      <th>L_quant</th>\n",
       "      <th>L_affect</th>\n",
       "      <th>L_posemo</th>\n",
       "      <th>L_negemo</th>\n",
       "      <th>L_anx</th>\n",
       "      <th>L_anger</th>\n",
       "      <th>L_sad</th>\n",
       "      <th>L_social</th>\n",
       "      <th>L_family</th>\n",
       "      <th>L_friend</th>\n",
       "      <th>L_female</th>\n",
       "      <th>L_male</th>\n",
       "      <th>L_cogproc</th>\n",
       "      <th>L_insight</th>\n",
       "      <th>L_cause</th>\n",
       "      <th>L_discrep</th>\n",
       "      <th>L_tentat</th>\n",
       "      <th>L_certain</th>\n",
       "      <th>L_differ</th>\n",
       "      <th>L_percept</th>\n",
       "      <th>L_see</th>\n",
       "      <th>L_hear</th>\n",
       "      <th>L_feel</th>\n",
       "      <th>L_bio</th>\n",
       "      <th>L_body</th>\n",
       "      <th>L_health</th>\n",
       "      <th>L_sexual</th>\n",
       "      <th>L_ingest</th>\n",
       "      <th>L_drives</th>\n",
       "      <th>L_affiliation</th>\n",
       "      <th>L_achieve</th>\n",
       "      <th>L_power</th>\n",
       "      <th>L_reward</th>\n",
       "      <th>L_risk</th>\n",
       "      <th>L_focuspast</th>\n",
       "      <th>L_focuspresent</th>\n",
       "      <th>L_focusfuture</th>\n",
       "      <th>L_relativ</th>\n",
       "      <th>L_motion</th>\n",
       "      <th>L_space</th>\n",
       "      <th>L_time</th>\n",
       "      <th>L_work</th>\n",
       "      <th>L_leisure</th>\n",
       "      <th>L_home</th>\n",
       "      <th>L_money</th>\n",
       "      <th>L_relig</th>\n",
       "      <th>L_death</th>\n",
       "      <th>L_informal</th>\n",
       "      <th>L_swear</th>\n",
       "      <th>L_netspeak</th>\n",
       "      <th>L_assent</th>\n",
       "      <th>L_nonflu</th>\n",
       "      <th>L_filler</th>\n",
       "      <th>L_AllPunc</th>\n",
       "      <th>L_Period</th>\n",
       "      <th>L_Comma</th>\n",
       "      <th>L_Colon</th>\n",
       "      <th>L_SemiC</th>\n",
       "      <th>L_QMark</th>\n",
       "      <th>L_Exclam</th>\n",
       "      <th>L_Dash</th>\n",
       "      <th>L_Quote</th>\n",
       "      <th>L_Apostro</th>\n",
       "      <th>L_Parenth</th>\n",
       "      <th>L_OtherP</th>\n",
       "      <th>R_full_text_Flesch_reading_ease</th>\n",
       "      <th>R_full_text_Flesch_kincaid_grade</th>\n",
       "      <th>R_full_text_smog</th>\n",
       "      <th>R_full_text_gunning_fog</th>\n",
       "      <th>R_full_text_words_per_sentence</th>\n",
       "      <th>R_full_text_capitalized_words</th>\n",
       "      <th>R_full_text_lexicon</th>\n",
       "      <th>R_full_text_urls_counts</th>\n",
       "      <th>R_full_text_long_words</th>\n",
       "      <th>R_full_text_syllables</th>\n",
       "      <th>R_full_text_stop_words</th>\n",
       "      <th>R_full_text_sentences</th>\n",
       "      <th>R_full_text_linsear_write</th>\n",
       "      <th>R_full_text_automated_readability</th>\n",
       "      <th>R_full_text_characters_total</th>\n",
       "      <th>R_full_text_coleman_liax</th>\n",
       "      <th>R_full_text_difficult_words</th>\n",
       "      <th>R_full_text_words_total</th>\n",
       "      <th>T_totalTweets</th>\n",
       "      <th>T_totalRetweets</th>\n",
       "      <th>T_totalLikes</th>\n",
       "      <th>T_totalReplies</th>\n",
       "      <th>T_span</th>\n",
       "      <th>T_countWeekDay</th>\n",
       "      <th>T_countWeekEnd</th>\n",
       "      <th>T_countMonday</th>\n",
       "      <th>T_countTuesday</th>\n",
       "      <th>T_countWednesday</th>\n",
       "      <th>T_countThursday</th>\n",
       "      <th>T_countFriday</th>\n",
       "      <th>T_countSaturday</th>\n",
       "      <th>T_countSunday</th>\n",
       "      <th>T_avgTimeBetweenTweets</th>\n",
       "      <th>T_avgTimeOfNextTweet</th>\n",
       "      <th>T_timeAbsBin1count0to6</th>\n",
       "      <th>T_timeAbsBin2count6to12</th>\n",
       "      <th>T_timeAbsBin3count12to18</th>\n",
       "      <th>T_timeAbsBin4count18to24</th>\n",
       "      <th>T_timeAbsBin5count24plus</th>\n",
       "      <th>T_avgTweetsPerUniqUser</th>\n",
       "      <th>M_dollar</th>\n",
       "      <th>M_dblApostrophe</th>\n",
       "      <th>M_comma</th>\n",
       "      <th>M_-LRB-</th>\n",
       "      <th>M_-RRB-</th>\n",
       "      <th>M_dot</th>\n",
       "      <th>M_colon</th>\n",
       "      <th>M_ADD</th>\n",
       "      <th>M_AFX</th>\n",
       "      <th>M_CC</th>\n",
       "      <th>M_CD</th>\n",
       "      <th>M_DT</th>\n",
       "      <th>M_EX</th>\n",
       "      <th>M_FW</th>\n",
       "      <th>M_HYPH</th>\n",
       "      <th>M_IN</th>\n",
       "      <th>M_JJ</th>\n",
       "      <th>M_JJR</th>\n",
       "      <th>M_JJS</th>\n",
       "      <th>M_LS</th>\n",
       "      <th>M_MD</th>\n",
       "      <th>M_NFP</th>\n",
       "      <th>M_NN</th>\n",
       "      <th>M_NNP</th>\n",
       "      <th>M_NNPS</th>\n",
       "      <th>M_NNS</th>\n",
       "      <th>M_PDT</th>\n",
       "      <th>M_POS</th>\n",
       "      <th>M_PRP</th>\n",
       "      <th>M_PRP$</th>\n",
       "      <th>M_RB</th>\n",
       "      <th>M_RBR</th>\n",
       "      <th>M_RBS</th>\n",
       "      <th>M_RP</th>\n",
       "      <th>M_SYM</th>\n",
       "      <th>M_TO</th>\n",
       "      <th>M_UH</th>\n",
       "      <th>M_VB</th>\n",
       "      <th>M_VBD</th>\n",
       "      <th>M_VBG</th>\n",
       "      <th>M_VBN</th>\n",
       "      <th>M_VBP</th>\n",
       "      <th>M_VBZ</th>\n",
       "      <th>M_WDT</th>\n",
       "      <th>M_WP</th>\n",
       "      <th>M_WP$</th>\n",
       "      <th>M_WRB</th>\n",
       "      <th>M_XX</th>\n",
       "      <th>M__SP</th>\n",
       "      <th>M_dblSpecialApostrophe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nutritionfacts.org</td>\n",
       "      <td>https://nutritionfacts.org/audio/fighting-fatigue/</td>\n",
       "      <td>Reliable</td>\n",
       "      <td>1241</td>\n",
       "      <td>73.48</td>\n",
       "      <td>52.26</td>\n",
       "      <td>23.58</td>\n",
       "      <td>1.68</td>\n",
       "      <td>8.99</td>\n",
       "      <td>43.27</td>\n",
       "      <td>70.91</td>\n",
       "      <td>12.33</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.14</td>\n",
       "      <td>13.46</td>\n",
       "      <td>5.24</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.01</td>\n",
       "      <td>8.94</td>\n",
       "      <td>2.90</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.53</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>17.08</td>\n",
       "      <td>4.43</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.90</td>\n",
       "      <td>6.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.26</td>\n",
       "      <td>15.55</td>\n",
       "      <td>1.77</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.95</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.85</td>\n",
       "      <td>8.46</td>\n",
       "      <td>1.29</td>\n",
       "      <td>10.39</td>\n",
       "      <td>2.82</td>\n",
       "      <td>3.06</td>\n",
       "      <td>4.59</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.23</td>\n",
       "      <td>12.41</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.69</td>\n",
       "      <td>59.13</td>\n",
       "      <td>18.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16.438876</td>\n",
       "      <td>12.162963</td>\n",
       "      <td>110</td>\n",
       "      <td>1202</td>\n",
       "      <td>0</td>\n",
       "      <td>903</td>\n",
       "      <td>2551</td>\n",
       "      <td>10.901340</td>\n",
       "      <td>135</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>23.4</td>\n",
       "      <td>9648</td>\n",
       "      <td>20.77</td>\n",
       "      <td>393</td>\n",
       "      <td>1642</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>5651.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5651.250000</td>\n",
       "      <td>5651.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nutritionfacts.org</td>\n",
       "      <td>https://nutritionfacts.org/audio/new-thoughts-on-a-healthy-weight/</td>\n",
       "      <td>Reliable</td>\n",
       "      <td>1262</td>\n",
       "      <td>79.00</td>\n",
       "      <td>53.80</td>\n",
       "      <td>15.76</td>\n",
       "      <td>87.14</td>\n",
       "      <td>10.34</td>\n",
       "      <td>36.29</td>\n",
       "      <td>72.90</td>\n",
       "      <td>10.30</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2.54</td>\n",
       "      <td>12.60</td>\n",
       "      <td>7.21</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.09</td>\n",
       "      <td>4.75</td>\n",
       "      <td>7.05</td>\n",
       "      <td>5.31</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.55</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>14.74</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.30</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.93</td>\n",
       "      <td>21.47</td>\n",
       "      <td>2.46</td>\n",
       "      <td>4.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.80</td>\n",
       "      <td>10.46</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.41</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.14</td>\n",
       "      <td>6.42</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.75</td>\n",
       "      <td>1.74</td>\n",
       "      <td>3.72</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.08</td>\n",
       "      <td>9.59</td>\n",
       "      <td>12.76</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.85</td>\n",
       "      <td>65.38</td>\n",
       "      <td>16.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>15.443264</td>\n",
       "      <td>14.342105</td>\n",
       "      <td>75</td>\n",
       "      <td>1233</td>\n",
       "      <td>0</td>\n",
       "      <td>872</td>\n",
       "      <td>2403</td>\n",
       "      <td>10.948012</td>\n",
       "      <td>114</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>20.9</td>\n",
       "      <td>9323</td>\n",
       "      <td>18.28</td>\n",
       "      <td>315</td>\n",
       "      <td>1635</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>162</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>119</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>141</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>nutritionfacts.org</td>\n",
       "      <td>https://nutritionfacts.org/audio/the-latest-on-childrens-health/</td>\n",
       "      <td>Reliable</td>\n",
       "      <td>1306</td>\n",
       "      <td>75.75</td>\n",
       "      <td>56.09</td>\n",
       "      <td>26.05</td>\n",
       "      <td>39.46</td>\n",
       "      <td>11.36</td>\n",
       "      <td>38.82</td>\n",
       "      <td>73.43</td>\n",
       "      <td>11.56</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>3.45</td>\n",
       "      <td>4.44</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2.53</td>\n",
       "      <td>11.03</td>\n",
       "      <td>7.27</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.68</td>\n",
       "      <td>2.22</td>\n",
       "      <td>6.97</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>13.94</td>\n",
       "      <td>3.68</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.06</td>\n",
       "      <td>1.53</td>\n",
       "      <td>3.29</td>\n",
       "      <td>6.97</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.23</td>\n",
       "      <td>18.38</td>\n",
       "      <td>2.91</td>\n",
       "      <td>6.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.26</td>\n",
       "      <td>9.72</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.07</td>\n",
       "      <td>5.21</td>\n",
       "      <td>1.84</td>\n",
       "      <td>10.49</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.14</td>\n",
       "      <td>6.58</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.95</td>\n",
       "      <td>8.65</td>\n",
       "      <td>12.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3.75</td>\n",
       "      <td>65.37</td>\n",
       "      <td>18.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.316705</td>\n",
       "      <td>14.350427</td>\n",
       "      <td>98</td>\n",
       "      <td>1289</td>\n",
       "      <td>0</td>\n",
       "      <td>928</td>\n",
       "      <td>2559</td>\n",
       "      <td>10.661108</td>\n",
       "      <td>117</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>22.7</td>\n",
       "      <td>9923</td>\n",
       "      <td>19.15</td>\n",
       "      <td>360</td>\n",
       "      <td>1679</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>161</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>113</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>170</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>382</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>216</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>nutritionfacts.org</td>\n",
       "      <td>https://nutritionfacts.org/audio/beans-beans-the-truth-about-lectins/</td>\n",
       "      <td>Reliable</td>\n",
       "      <td>1879</td>\n",
       "      <td>76.11</td>\n",
       "      <td>52.55</td>\n",
       "      <td>16.33</td>\n",
       "      <td>29.33</td>\n",
       "      <td>10.56</td>\n",
       "      <td>36.56</td>\n",
       "      <td>72.43</td>\n",
       "      <td>12.13</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.18</td>\n",
       "      <td>14.58</td>\n",
       "      <td>5.80</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.61</td>\n",
       "      <td>6.87</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.48</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.11</td>\n",
       "      <td>16.60</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.77</td>\n",
       "      <td>3.41</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.69</td>\n",
       "      <td>17.88</td>\n",
       "      <td>2.55</td>\n",
       "      <td>7.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>8.99</td>\n",
       "      <td>6.97</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.61</td>\n",
       "      <td>8.52</td>\n",
       "      <td>1.38</td>\n",
       "      <td>9.47</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.98</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>31.88</td>\n",
       "      <td>9.42</td>\n",
       "      <td>15.11</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.77</td>\n",
       "      <td>73.40</td>\n",
       "      <td>18.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>15.006575</td>\n",
       "      <td>14.775148</td>\n",
       "      <td>130</td>\n",
       "      <td>1840</td>\n",
       "      <td>0</td>\n",
       "      <td>1357</td>\n",
       "      <td>3544</td>\n",
       "      <td>7.168602</td>\n",
       "      <td>169</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.7</td>\n",
       "      <td>14145</td>\n",
       "      <td>18.98</td>\n",
       "      <td>443</td>\n",
       "      <td>2497</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>18664.183333</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2666.311905</td>\n",
       "      <td>7235.495238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>284</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>176</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>244</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>494</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>321</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>132</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>nutritionfacts.org</td>\n",
       "      <td>https://nutritionfacts.org/audio/new-research-on-cholesterol/</td>\n",
       "      <td>Reliable</td>\n",
       "      <td>1475</td>\n",
       "      <td>76.03</td>\n",
       "      <td>53.25</td>\n",
       "      <td>32.67</td>\n",
       "      <td>37.78</td>\n",
       "      <td>9.77</td>\n",
       "      <td>39.66</td>\n",
       "      <td>70.31</td>\n",
       "      <td>12.07</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.17</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.71</td>\n",
       "      <td>13.02</td>\n",
       "      <td>5.63</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.34</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.78</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.34</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5.83</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>14.24</td>\n",
       "      <td>3.73</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.56</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>15.39</td>\n",
       "      <td>2.92</td>\n",
       "      <td>9.56</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.39</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.78</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.51</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1.15</td>\n",
       "      <td>12.88</td>\n",
       "      <td>2.31</td>\n",
       "      <td>4.68</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.85</td>\n",
       "      <td>10.85</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.42</td>\n",
       "      <td>65.78</td>\n",
       "      <td>20.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>15.537061</td>\n",
       "      <td>13.943662</td>\n",
       "      <td>94</td>\n",
       "      <td>1435</td>\n",
       "      <td>0</td>\n",
       "      <td>1038</td>\n",
       "      <td>2938</td>\n",
       "      <td>9.040404</td>\n",
       "      <td>142</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>26.4</td>\n",
       "      <td>11351</td>\n",
       "      <td>20.03</td>\n",
       "      <td>394</td>\n",
       "      <td>1980</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>11813.533333</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2953.383333</td>\n",
       "      <td>3708.545833</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>193</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>138</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>446</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>187</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               domain  \\\n",
       "0  nutritionfacts.org   \n",
       "1  nutritionfacts.org   \n",
       "2  nutritionfacts.org   \n",
       "3  nutritionfacts.org   \n",
       "4  nutritionfacts.org   \n",
       "\n",
       "                                                                     url  \\\n",
       "0  https://nutritionfacts.org/audio/fighting-fatigue/                      \n",
       "1  https://nutritionfacts.org/audio/new-thoughts-on-a-healthy-weight/      \n",
       "2  https://nutritionfacts.org/audio/the-latest-on-childrens-health/        \n",
       "3  https://nutritionfacts.org/audio/beans-beans-the-truth-about-lectins/   \n",
       "4  https://nutritionfacts.org/audio/new-research-on-cholesterol/           \n",
       "\n",
       "    urlType  L_WC  L_Analytic  L_Clout  L_Authentic  L_Tone  L_WPS  L_Sixltr  \\\n",
       "0  Reliable  1241  73.48       52.26    23.58        1.68    8.99   43.27      \n",
       "1  Reliable  1262  79.00       53.80    15.76        87.14   10.34  36.29      \n",
       "2  Reliable  1306  75.75       56.09    26.05        39.46   11.36  38.82      \n",
       "3  Reliable  1879  76.11       52.55    16.33        29.33   10.56  36.56      \n",
       "4  Reliable  1475  76.03       53.25    32.67        37.78   9.77   39.66      \n",
       "\n",
       "   L_Dic  L_function  L_pronoun  L_ppron   L_i  L_we  L_you  L_shehe  L_they  \\\n",
       "0  70.91  12.33       2.01       1.13     0.32  0.24  0.32   0.0      0.24     \n",
       "1  72.90  10.30       1.74       0.79     0.24  0.16  0.32   0.0      0.08     \n",
       "2  73.43  11.56       1.07       0.46     0.23  0.00  0.23   0.0      0.00     \n",
       "3  72.43  12.13       2.02       0.90     0.27  0.32  0.32   0.0      0.00     \n",
       "4  70.31  12.07       2.51       1.29     0.27  0.54  0.41   0.0      0.07     \n",
       "\n",
       "   L_ipron  L_article  L_prep  L_auxverb  L_adverb  L_conj  L_negate  L_verb  \\\n",
       "0  0.89     0.0        1.85    3.38       4.35      1.13    3.14      13.46    \n",
       "1  0.95     0.0        1.51    3.09       3.33      0.48    2.54      12.60    \n",
       "2  0.61     0.0        1.68    3.45       4.44      1.38    2.53      11.03    \n",
       "3  1.12     0.0        1.81    3.99       3.73      0.90    2.18      14.58    \n",
       "4  1.22     0.0        2.17    3.25       3.59      1.15    2.71      13.02    \n",
       "\n",
       "   L_adj  L_compare  L_interrog  L_number  L_quant  L_affect  L_posemo  \\\n",
       "0  5.24   1.93       0.32        2.34      2.01     8.94      2.90       \n",
       "1  7.21   3.49       0.24        3.09      4.75     7.05      5.31       \n",
       "2  7.27   4.29       0.31        3.68      2.22     6.97      3.83       \n",
       "3  5.80   2.34       0.32        3.67      2.61     6.87      3.46       \n",
       "4  5.63   2.78       0.34        4.61      2.78     8.00      4.34       \n",
       "\n",
       "   L_negemo  L_anx  L_anger  L_sad  L_social  L_family  L_friend  L_female  \\\n",
       "0  5.88      0.73   0.81     1.53   6.37      0.16      0.08      0.08       \n",
       "1  1.74      0.79   0.00     0.79   5.55      0.08      0.00      0.32       \n",
       "2  3.06      0.77   0.38     0.46   7.50      0.31      0.54      0.23       \n",
       "3  3.25      0.64   0.90     0.48   5.22      0.05      0.05      0.21       \n",
       "4  3.66      1.22   0.54     0.95   5.83      0.34      0.00      0.20       \n",
       "\n",
       "   L_male  L_cogproc  L_insight  L_cause  L_discrep  L_tentat  L_certain  \\\n",
       "0  0.16    17.08      4.43       3.95     1.37       3.06      2.34        \n",
       "1  0.24    14.74      3.49       4.36     0.79       2.61      2.22        \n",
       "2  0.08    13.94      3.68       2.76     0.54       3.06      1.53        \n",
       "3  0.11    16.60      4.26       3.19     1.65       3.25      2.45        \n",
       "4  0.34    14.24      3.73       2.98     1.56       2.85      1.56        \n",
       "\n",
       "   L_differ  L_percept  L_see  L_hear  L_feel  L_bio  L_body  L_health  \\\n",
       "0  2.90      6.04       2.01   0.24    2.26    15.55  1.77    10.56      \n",
       "1  2.30      4.36       0.63   0.40    2.93    21.47  2.46    4.28       \n",
       "2  3.29      6.97       1.53   0.61    1.23    18.38  2.91    6.97       \n",
       "3  2.77      3.41       1.81   0.48    0.69    17.88  2.55    7.18       \n",
       "4  2.98      3.12       1.22   0.54    0.41    15.39  2.92    9.56       \n",
       "\n",
       "   L_sexual  L_ingest  L_drives  L_affiliation  L_achieve  L_power  L_reward  \\\n",
       "0  0.24      3.95      7.90      1.53           1.53       2.01     2.01       \n",
       "1  0.00      16.80     10.46     1.51           3.41       3.72     3.41       \n",
       "2  0.00      9.26      9.72      1.30           2.60       3.45     1.38       \n",
       "3  0.16      8.99      6.97      0.80           1.81       1.54     1.86       \n",
       "4  0.41      3.39      9.02      1.36           2.03       2.78     1.90       \n",
       "\n",
       "   L_risk  L_focuspast  L_focuspresent  L_focusfuture  L_relativ  L_motion  \\\n",
       "0  1.53    1.85         8.46            1.29           10.39      2.82       \n",
       "1  1.19    2.14         6.42            1.35           9.75       1.74       \n",
       "2  2.30    2.07         5.21            1.84           10.49      1.84       \n",
       "3  1.81    2.61         8.52            1.38           9.47       2.13       \n",
       "4  1.69    2.51         7.39            1.15           12.88      2.31       \n",
       "\n",
       "   L_space  L_time  L_work  L_leisure  L_home  L_money  L_relig  L_death  \\\n",
       "0  3.06     4.59    3.87    1.69       0.40    0.40     0.00     0.16      \n",
       "1  3.72     4.28    3.72    0.63       0.00    0.40     0.00     0.00      \n",
       "2  2.14     6.58    5.13    0.84       0.84    0.46     0.00     0.08      \n",
       "3  2.98     4.58    4.04    2.08       0.11    0.96     0.00     0.48      \n",
       "4  4.68     6.10    3.86    0.95       0.00    1.22     0.07     0.27      \n",
       "\n",
       "   L_informal  L_swear  L_netspeak  L_assent  L_nonflu  L_filler  L_AllPunc  \\\n",
       "0  0.73        0.00     0.00        0.56      0.08      0.00      32.23       \n",
       "1  0.48        0.00     0.08        0.32      0.08      0.00      29.08       \n",
       "2  0.84        0.15     0.00        0.15      0.46      0.00      27.95       \n",
       "3  0.64        0.00     0.00        0.37      0.21      0.05      31.88       \n",
       "4  0.61        0.00     0.00        0.20      0.34      0.00      34.85       \n",
       "\n",
       "   L_Period  L_Comma  L_Colon  L_SemiC  L_QMark  L_Exclam  L_Dash  L_Quote  \\\n",
       "0  12.41     13.94    0.32     0.56     0.73     0.00      2.58    0.0       \n",
       "1  9.59      12.76    0.24     0.24     1.11     0.08      2.22    0.0       \n",
       "2  8.65      12.25    0.31     0.31     0.92     0.00      1.30    0.0       \n",
       "3  9.42      15.11    0.27     0.48     1.28     0.11      2.02    0.0       \n",
       "4  10.85     12.95    0.27     0.68     1.22     0.27      3.19    0.0       \n",
       "\n",
       "   L_Apostro  L_Parenth  L_OtherP  R_full_text_Flesch_reading_ease  \\\n",
       "0  0          0.00       1.69      59.13                             \n",
       "1  0          0.00       2.85      65.38                             \n",
       "2  0          0.46       3.75      65.37                             \n",
       "3  0          0.43       2.77      73.40                             \n",
       "4  0          0.00       5.42      65.78                             \n",
       "\n",
       "   R_full_text_Flesch_kincaid_grade  R_full_text_smog  \\\n",
       "0  18.9                              17.6               \n",
       "1  16.5                              15.2               \n",
       "2  18.5                              16.0               \n",
       "3  18.2                              16.2               \n",
       "4  20.7                              17.7               \n",
       "\n",
       "   R_full_text_gunning_fog  R_full_text_words_per_sentence  \\\n",
       "0  16.438876                12.162963                        \n",
       "1  15.443264                14.342105                        \n",
       "2  16.316705                14.350427                        \n",
       "3  15.006575                14.775148                        \n",
       "4  15.537061                13.943662                        \n",
       "\n",
       "   R_full_text_capitalized_words  R_full_text_lexicon  \\\n",
       "0  110                            1202                  \n",
       "1  75                             1233                  \n",
       "2  98                             1289                  \n",
       "3  130                            1840                  \n",
       "4  94                             1435                  \n",
       "\n",
       "   R_full_text_urls_counts  R_full_text_long_words  R_full_text_syllables  \\\n",
       "0  0                        903                     2551                    \n",
       "1  0                        872                     2403                    \n",
       "2  0                        928                     2559                    \n",
       "3  0                        1357                    3544                    \n",
       "4  0                        1038                    2938                    \n",
       "\n",
       "   R_full_text_stop_words  R_full_text_sentences  R_full_text_linsear_write  \\\n",
       "0  10.901340               135                    11.142857                   \n",
       "1  10.948012               114                    8.714286                    \n",
       "2  10.661108               117                    7.750000                    \n",
       "3  7.168602                169                    12.000000                   \n",
       "4  9.040404                142                    12.000000                   \n",
       "\n",
       "   R_full_text_automated_readability  R_full_text_characters_total  \\\n",
       "0  23.4                               9648                           \n",
       "1  20.9                               9323                           \n",
       "2  22.7                               9923                           \n",
       "3  23.7                               14145                          \n",
       "4  26.4                               11351                          \n",
       "\n",
       "   R_full_text_coleman_liax  R_full_text_difficult_words  \\\n",
       "0  20.77                     393                           \n",
       "1  18.28                     315                           \n",
       "2  19.15                     360                           \n",
       "3  18.98                     443                           \n",
       "4  20.03                     394                           \n",
       "\n",
       "   R_full_text_words_total  T_totalTweets  T_totalRetweets  T_totalLikes  \\\n",
       "0  1642                     2              26               70             \n",
       "1  1635                     1              26               61             \n",
       "2  1679                     2              24               62             \n",
       "3  2497                     8              20               44             \n",
       "4  1980                     5              38               93             \n",
       "\n",
       "   T_totalReplies        T_span  T_countWeekDay  T_countWeekEnd  \\\n",
       "0  0               5651.250000   1               1                \n",
       "1  1              -1.000000      1               0                \n",
       "2  1               5.333333      2               0                \n",
       "3  3               18664.183333  8               0                \n",
       "4  2               11813.533333  2               3                \n",
       "\n",
       "   T_countMonday  T_countTuesday  T_countWednesday  T_countThursday  \\\n",
       "0  0              0               1                 0                 \n",
       "1  0              0               0                 0                 \n",
       "2  0              0               0                 0                 \n",
       "3  0              1               0                 6                 \n",
       "4  1              0               0                 0                 \n",
       "\n",
       "   T_countFriday  T_countSaturday  T_countSunday  T_avgTimeBetweenTweets  \\\n",
       "0  0              0                1              5651.250000              \n",
       "1  1              0                0             -1.000000                 \n",
       "2  2              0                0              5.333333                 \n",
       "3  1              0                0              2666.311905              \n",
       "4  1              3                0              2953.383333              \n",
       "\n",
       "   T_avgTimeOfNextTweet  T_timeAbsBin1count0to6  T_timeAbsBin2count6to12  \\\n",
       "0  5651.250000           1                       0                         \n",
       "1 -1.000000              1                       0                         \n",
       "2  5.333333              2                       0                         \n",
       "3  7235.495238           1                       1                         \n",
       "4  3708.545833           3                       0                         \n",
       "\n",
       "   T_timeAbsBin3count12to18  T_timeAbsBin4count18to24  \\\n",
       "0  0                         0                          \n",
       "1  0                         0                          \n",
       "2  0                         0                          \n",
       "3  1                         0                          \n",
       "4  0                         0                          \n",
       "\n",
       "   T_timeAbsBin5count24plus  T_avgTweetsPerUniqUser  M_dollar  \\\n",
       "0  1                         1.0                    -1          \n",
       "1  0                         1.0                    -1          \n",
       "2  0                         1.0                     1          \n",
       "3  5                         1.0                     4          \n",
       "4  2                         1.0                     2          \n",
       "\n",
       "   M_dblApostrophe  M_comma  M_-LRB-  M_-RRB-  M_dot  M_colon  M_ADD  M_AFX  \\\n",
       "0 -1                174      7        7        128    18      -1     -1       \n",
       "1 -1                162      17       17       119    8       -1     -1       \n",
       "2 -1                161      25       25       113    8       -1     -1       \n",
       "3 -1                284      25       25       176    18      -1     -1       \n",
       "4 -1                193      35       35       138    21      -1     -1       \n",
       "\n",
       "   M_CC  M_CD  M_DT  M_EX  M_FW  M_HYPH  M_IN  M_JJ  M_JJR  M_JJS  M_LS  M_MD  \\\n",
       "0  3     22    14    4    -1     24      26    187   2      2      1     15     \n",
       "1  2     33    9     3     3     26      19    141   30     5      1     23     \n",
       "2  3     36    8     5     1     14      24    170   18     5      1     22     \n",
       "3  6     58    18    3    -1     30      29    244   8      8     -1     42     \n",
       "4  3     51    13    1     1     38      28    200   11     3     -1     18     \n",
       "\n",
       "   M_NFP  M_NN  M_NNP  M_NNPS  M_NNS  M_PDT  M_POS  M_PRP  M_PRP$  M_RB  \\\n",
       "0  1      396   81     4       148   -1     -1      14    -1       98     \n",
       "1  1      423   46     5       180   -1     -1      11    -1       74     \n",
       "2  2      382   61     5       216   -1     -1      7     -1       98     \n",
       "3  3      494   71     8       321   -1     -1      21    -1       137    \n",
       "4  3      446   68     7       187   -1     -1      21     1       114    \n",
       "\n",
       "   M_RBR  M_RBS  M_RP  M_SYM  M_TO  M_UH  M_VB  M_VBD  M_VBG  M_VBN  M_VBP  \\\n",
       "0  1     -1      1     4      1     10    69    29     38     36     38      \n",
       "1  3     -1      1    -1     -1     12    72    42     60     24     40      \n",
       "2  4      3     -1    -1     -1     9     52    41     58     40     34      \n",
       "3  4      3      1    -1     -1     23    132   55     55     76     69      \n",
       "4  1      2      2    -1     -1     12    83    47     53     46     49      \n",
       "\n",
       "   M_VBZ  M_WDT  M_WP  M_WP$  M_WRB  M_XX  M__SP  M_dblSpecialApostrophe  \n",
       "0  36    -1      1     1      1     -1    -1     -1                       \n",
       "1  20     1     -1     1      1     -1    -1     -1                       \n",
       "2  25    -1     -1     1      1     -1    -1     -1                       \n",
       "3  41     2     -1     1      2     -1    -1     -1                       \n",
       "4  42     4     -1     1     -1     -1    -1     -1                       "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>urlType</th>\n",
       "      <th>L_WC</th>\n",
       "      <th>L_Analytic</th>\n",
       "      <th>L_Clout</th>\n",
       "      <th>L_Authentic</th>\n",
       "      <th>L_Tone</th>\n",
       "      <th>L_WPS</th>\n",
       "      <th>L_Sixltr</th>\n",
       "      <th>L_Dic</th>\n",
       "      <th>L_function</th>\n",
       "      <th>L_pronoun</th>\n",
       "      <th>L_ppron</th>\n",
       "      <th>L_i</th>\n",
       "      <th>L_we</th>\n",
       "      <th>L_you</th>\n",
       "      <th>L_shehe</th>\n",
       "      <th>L_they</th>\n",
       "      <th>L_ipron</th>\n",
       "      <th>L_article</th>\n",
       "      <th>L_prep</th>\n",
       "      <th>L_auxverb</th>\n",
       "      <th>L_adverb</th>\n",
       "      <th>L_conj</th>\n",
       "      <th>L_negate</th>\n",
       "      <th>L_verb</th>\n",
       "      <th>L_adj</th>\n",
       "      <th>L_compare</th>\n",
       "      <th>L_interrog</th>\n",
       "      <th>L_number</th>\n",
       "      <th>L_quant</th>\n",
       "      <th>L_affect</th>\n",
       "      <th>L_posemo</th>\n",
       "      <th>L_negemo</th>\n",
       "      <th>L_anx</th>\n",
       "      <th>L_anger</th>\n",
       "      <th>L_sad</th>\n",
       "      <th>L_social</th>\n",
       "      <th>L_family</th>\n",
       "      <th>L_friend</th>\n",
       "      <th>L_female</th>\n",
       "      <th>L_male</th>\n",
       "      <th>L_cogproc</th>\n",
       "      <th>L_insight</th>\n",
       "      <th>L_cause</th>\n",
       "      <th>L_discrep</th>\n",
       "      <th>L_tentat</th>\n",
       "      <th>L_certain</th>\n",
       "      <th>L_differ</th>\n",
       "      <th>L_percept</th>\n",
       "      <th>L_see</th>\n",
       "      <th>L_hear</th>\n",
       "      <th>L_feel</th>\n",
       "      <th>L_bio</th>\n",
       "      <th>L_body</th>\n",
       "      <th>L_health</th>\n",
       "      <th>L_sexual</th>\n",
       "      <th>L_ingest</th>\n",
       "      <th>L_drives</th>\n",
       "      <th>L_affiliation</th>\n",
       "      <th>L_achieve</th>\n",
       "      <th>L_power</th>\n",
       "      <th>L_reward</th>\n",
       "      <th>L_risk</th>\n",
       "      <th>L_focuspast</th>\n",
       "      <th>L_focuspresent</th>\n",
       "      <th>L_focusfuture</th>\n",
       "      <th>L_relativ</th>\n",
       "      <th>L_motion</th>\n",
       "      <th>L_space</th>\n",
       "      <th>L_time</th>\n",
       "      <th>L_work</th>\n",
       "      <th>L_leisure</th>\n",
       "      <th>L_home</th>\n",
       "      <th>L_money</th>\n",
       "      <th>L_relig</th>\n",
       "      <th>L_death</th>\n",
       "      <th>L_informal</th>\n",
       "      <th>L_swear</th>\n",
       "      <th>L_netspeak</th>\n",
       "      <th>L_assent</th>\n",
       "      <th>L_nonflu</th>\n",
       "      <th>L_filler</th>\n",
       "      <th>L_AllPunc</th>\n",
       "      <th>L_Period</th>\n",
       "      <th>L_Comma</th>\n",
       "      <th>L_Colon</th>\n",
       "      <th>L_SemiC</th>\n",
       "      <th>L_QMark</th>\n",
       "      <th>L_Exclam</th>\n",
       "      <th>L_Dash</th>\n",
       "      <th>L_Quote</th>\n",
       "      <th>L_Apostro</th>\n",
       "      <th>L_Parenth</th>\n",
       "      <th>L_OtherP</th>\n",
       "      <th>R_full_text_Flesch_reading_ease</th>\n",
       "      <th>R_full_text_Flesch_kincaid_grade</th>\n",
       "      <th>R_full_text_smog</th>\n",
       "      <th>R_full_text_gunning_fog</th>\n",
       "      <th>R_full_text_words_per_sentence</th>\n",
       "      <th>R_full_text_capitalized_words</th>\n",
       "      <th>R_full_text_lexicon</th>\n",
       "      <th>R_full_text_urls_counts</th>\n",
       "      <th>R_full_text_long_words</th>\n",
       "      <th>R_full_text_syllables</th>\n",
       "      <th>R_full_text_stop_words</th>\n",
       "      <th>R_full_text_sentences</th>\n",
       "      <th>R_full_text_linsear_write</th>\n",
       "      <th>R_full_text_automated_readability</th>\n",
       "      <th>R_full_text_characters_total</th>\n",
       "      <th>R_full_text_coleman_liax</th>\n",
       "      <th>R_full_text_difficult_words</th>\n",
       "      <th>R_full_text_words_total</th>\n",
       "      <th>T_totalTweets</th>\n",
       "      <th>T_totalRetweets</th>\n",
       "      <th>T_totalLikes</th>\n",
       "      <th>T_totalReplies</th>\n",
       "      <th>T_span</th>\n",
       "      <th>T_countWeekDay</th>\n",
       "      <th>T_countWeekEnd</th>\n",
       "      <th>T_countMonday</th>\n",
       "      <th>T_countTuesday</th>\n",
       "      <th>T_countWednesday</th>\n",
       "      <th>T_countThursday</th>\n",
       "      <th>T_countFriday</th>\n",
       "      <th>T_countSaturday</th>\n",
       "      <th>T_countSunday</th>\n",
       "      <th>T_avgTimeBetweenTweets</th>\n",
       "      <th>T_avgTimeOfNextTweet</th>\n",
       "      <th>T_timeAbsBin1count0to6</th>\n",
       "      <th>T_timeAbsBin2count6to12</th>\n",
       "      <th>T_timeAbsBin3count12to18</th>\n",
       "      <th>T_timeAbsBin4count18to24</th>\n",
       "      <th>T_timeAbsBin5count24plus</th>\n",
       "      <th>T_avgTweetsPerUniqUser</th>\n",
       "      <th>M_dollar</th>\n",
       "      <th>M_dblApostrophe</th>\n",
       "      <th>M_comma</th>\n",
       "      <th>M_-LRB-</th>\n",
       "      <th>M_-RRB-</th>\n",
       "      <th>M_dot</th>\n",
       "      <th>M_colon</th>\n",
       "      <th>M_ADD</th>\n",
       "      <th>M_AFX</th>\n",
       "      <th>M_CC</th>\n",
       "      <th>M_CD</th>\n",
       "      <th>M_DT</th>\n",
       "      <th>M_EX</th>\n",
       "      <th>M_FW</th>\n",
       "      <th>M_HYPH</th>\n",
       "      <th>M_IN</th>\n",
       "      <th>M_JJ</th>\n",
       "      <th>M_JJR</th>\n",
       "      <th>M_JJS</th>\n",
       "      <th>M_LS</th>\n",
       "      <th>M_MD</th>\n",
       "      <th>M_NFP</th>\n",
       "      <th>M_NN</th>\n",
       "      <th>M_NNP</th>\n",
       "      <th>M_NNPS</th>\n",
       "      <th>M_NNS</th>\n",
       "      <th>M_PDT</th>\n",
       "      <th>M_POS</th>\n",
       "      <th>M_PRP</th>\n",
       "      <th>M_PRP$</th>\n",
       "      <th>M_RB</th>\n",
       "      <th>M_RBR</th>\n",
       "      <th>M_RBS</th>\n",
       "      <th>M_RP</th>\n",
       "      <th>M_SYM</th>\n",
       "      <th>M_TO</th>\n",
       "      <th>M_UH</th>\n",
       "      <th>M_VB</th>\n",
       "      <th>M_VBD</th>\n",
       "      <th>M_VBG</th>\n",
       "      <th>M_VBN</th>\n",
       "      <th>M_VBP</th>\n",
       "      <th>M_VBZ</th>\n",
       "      <th>M_WDT</th>\n",
       "      <th>M_WP</th>\n",
       "      <th>M_WP$</th>\n",
       "      <th>M_WRB</th>\n",
       "      <th>M_XX</th>\n",
       "      <th>M__SP</th>\n",
       "      <th>M_dblSpecialApostrophe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10944</td>\n",
       "      <td>thetruthdivision.com</td>\n",
       "      <td>http://thetruthdivision.com/2016/12/shock-trump-supporter-scott-baio-attacked-for-political-beliefs-files-police-report/</td>\n",
       "      <td>Fake</td>\n",
       "      <td>157</td>\n",
       "      <td>90.55</td>\n",
       "      <td>79.61</td>\n",
       "      <td>5.62</td>\n",
       "      <td>37.02</td>\n",
       "      <td>10.47</td>\n",
       "      <td>40.76</td>\n",
       "      <td>57.96</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.27</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>12.74</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.10</td>\n",
       "      <td>6.37</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.28</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.64</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>15.92</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.55</td>\n",
       "      <td>8.28</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.27</td>\n",
       "      <td>3.18</td>\n",
       "      <td>7.01</td>\n",
       "      <td>0.64</td>\n",
       "      <td>10.83</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>7.64</td>\n",
       "      <td>6.37</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.03</td>\n",
       "      <td>11.46</td>\n",
       "      <td>7.01</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.91</td>\n",
       "      <td>60.88</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>20.067216</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>51</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>274</td>\n",
       "      <td>107.185629</td>\n",
       "      <td>16</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1158</td>\n",
       "      <td>21.92</td>\n",
       "      <td>58</td>\n",
       "      <td>167</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>16.766667</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.794444</td>\n",
       "      <td>3.580556</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10945</td>\n",
       "      <td>thetruthdivision.com</td>\n",
       "      <td>http://thetruthdivision.com/2017/02/breaking-teacher-fired-shocking-statement-trump-supporters/</td>\n",
       "      <td>Fake</td>\n",
       "      <td>124</td>\n",
       "      <td>91.63</td>\n",
       "      <td>90.14</td>\n",
       "      <td>34.13</td>\n",
       "      <td>83.22</td>\n",
       "      <td>12.40</td>\n",
       "      <td>53.23</td>\n",
       "      <td>63.71</td>\n",
       "      <td>6.45</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>11.29</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>11.29</td>\n",
       "      <td>7.26</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.06</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.13</td>\n",
       "      <td>4.84</td>\n",
       "      <td>2.42</td>\n",
       "      <td>6.45</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>6.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.13</td>\n",
       "      <td>4.03</td>\n",
       "      <td>6.45</td>\n",
       "      <td>4.84</td>\n",
       "      <td>12.90</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.61</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.45</td>\n",
       "      <td>10.48</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>9.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.42</td>\n",
       "      <td>44.64</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.450999</td>\n",
       "      <td>9.769231</td>\n",
       "      <td>30</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>233</td>\n",
       "      <td>140.944882</td>\n",
       "      <td>13</td>\n",
       "      <td>10.428571</td>\n",
       "      <td>23.8</td>\n",
       "      <td>986</td>\n",
       "      <td>27.13</td>\n",
       "      <td>43</td>\n",
       "      <td>127</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6.716667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.679167</td>\n",
       "      <td>3.108333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10946</td>\n",
       "      <td>thetruthdivision.com</td>\n",
       "      <td>http://thetruthdivision.com/2016/11/obama-tells-trump-presidency-cant-treated-casually-golfs-324-times/</td>\n",
       "      <td>Fake</td>\n",
       "      <td>145</td>\n",
       "      <td>80.39</td>\n",
       "      <td>55.48</td>\n",
       "      <td>13.87</td>\n",
       "      <td>37.99</td>\n",
       "      <td>16.11</td>\n",
       "      <td>37.93</td>\n",
       "      <td>60.00</td>\n",
       "      <td>10.34</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>3.45</td>\n",
       "      <td>8.97</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.28</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.97</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.83</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>18.62</td>\n",
       "      <td>4.83</td>\n",
       "      <td>2.76</td>\n",
       "      <td>11.03</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.38</td>\n",
       "      <td>5.52</td>\n",
       "      <td>1.38</td>\n",
       "      <td>9.66</td>\n",
       "      <td>6.21</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.14</td>\n",
       "      <td>11.03</td>\n",
       "      <td>6.21</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.48</td>\n",
       "      <td>11.03</td>\n",
       "      <td>7.59</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>4.83</td>\n",
       "      <td>39.98</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>18.884695</td>\n",
       "      <td>14.363636</td>\n",
       "      <td>36</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>281</td>\n",
       "      <td>113.291139</td>\n",
       "      <td>11</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1071</td>\n",
       "      <td>23.14</td>\n",
       "      <td>44</td>\n",
       "      <td>158</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>1432.600000</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>55.100000</td>\n",
       "      <td>85.323077</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10947</td>\n",
       "      <td>thetruthdivision.com</td>\n",
       "      <td>http://thetruthdivision.com/2017/03/just-trumps-golf-course-vandalized/</td>\n",
       "      <td>Fake</td>\n",
       "      <td>151</td>\n",
       "      <td>89.60</td>\n",
       "      <td>78.67</td>\n",
       "      <td>19.75</td>\n",
       "      <td>50.49</td>\n",
       "      <td>11.62</td>\n",
       "      <td>38.41</td>\n",
       "      <td>61.59</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4.64</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.96</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3.31</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>12.58</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.32</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.57</td>\n",
       "      <td>1.99</td>\n",
       "      <td>6.62</td>\n",
       "      <td>4.64</td>\n",
       "      <td>9.27</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.77</td>\n",
       "      <td>10.60</td>\n",
       "      <td>6.62</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>50.76</td>\n",
       "      <td>16.2</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.333954</td>\n",
       "      <td>12.076923</td>\n",
       "      <td>37</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>268</td>\n",
       "      <td>114.012739</td>\n",
       "      <td>13</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1121</td>\n",
       "      <td>24.76</td>\n",
       "      <td>53</td>\n",
       "      <td>157</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13.950000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.743750</td>\n",
       "      <td>3.783333</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10948</td>\n",
       "      <td>thetruthdivision.com</td>\n",
       "      <td>http://thetruthdivision.com/2017/05/popular-game-show-host-requests-new-provision-added-acha-liberals-ticked/</td>\n",
       "      <td>Fake</td>\n",
       "      <td>84</td>\n",
       "      <td>89.26</td>\n",
       "      <td>96.27</td>\n",
       "      <td>9.40</td>\n",
       "      <td>95.81</td>\n",
       "      <td>9.33</td>\n",
       "      <td>42.86</td>\n",
       "      <td>58.33</td>\n",
       "      <td>4.76</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.90</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>9.52</td>\n",
       "      <td>7.14</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.95</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.33</td>\n",
       "      <td>4.76</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.90</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5.95</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.10</td>\n",
       "      <td>2.38</td>\n",
       "      <td>9.52</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.38</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.19</td>\n",
       "      <td>13.10</td>\n",
       "      <td>5.95</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>70.43</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>19.337688</td>\n",
       "      <td>9.363636</td>\n",
       "      <td>35</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>154</td>\n",
       "      <td>173.786408</td>\n",
       "      <td>11</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>17.1</td>\n",
       "      <td>624</td>\n",
       "      <td>18.15</td>\n",
       "      <td>35</td>\n",
       "      <td>103</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>719.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.966667</td>\n",
       "      <td>284.386667</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     domain  \\\n",
       "10944  thetruthdivision.com   \n",
       "10945  thetruthdivision.com   \n",
       "10946  thetruthdivision.com   \n",
       "10947  thetruthdivision.com   \n",
       "10948  thetruthdivision.com   \n",
       "\n",
       "                                                                                                                            url  \\\n",
       "10944  http://thetruthdivision.com/2016/12/shock-trump-supporter-scott-baio-attacked-for-political-beliefs-files-police-report/   \n",
       "10945  http://thetruthdivision.com/2017/02/breaking-teacher-fired-shocking-statement-trump-supporters/                            \n",
       "10946  http://thetruthdivision.com/2016/11/obama-tells-trump-presidency-cant-treated-casually-golfs-324-times/                    \n",
       "10947  http://thetruthdivision.com/2017/03/just-trumps-golf-course-vandalized/                                                    \n",
       "10948  http://thetruthdivision.com/2017/05/popular-game-show-host-requests-new-provision-added-acha-liberals-ticked/              \n",
       "\n",
       "      urlType  L_WC  L_Analytic  L_Clout  L_Authentic  L_Tone  L_WPS  \\\n",
       "10944  Fake    157   90.55       79.61    5.62         37.02   10.47   \n",
       "10945  Fake    124   91.63       90.14    34.13        83.22   12.40   \n",
       "10946  Fake    145   80.39       55.48    13.87        37.99   16.11   \n",
       "10947  Fake    151   89.60       78.67    19.75        50.49   11.62   \n",
       "10948  Fake    84    89.26       96.27    9.40         95.81   9.33    \n",
       "\n",
       "       L_Sixltr  L_Dic  L_function  L_pronoun  L_ppron  L_i  L_we  L_you  \\\n",
       "10944  40.76     57.96  5.73        0.00       0.00     0.0  0.00  0.00    \n",
       "10945  53.23     63.71  6.45        0.81       0.00     0.0  0.00  0.00    \n",
       "10946  37.93     60.00  10.34       2.07       0.69     0.0  0.69  0.00    \n",
       "10947  38.41     61.59  5.96        0.00       0.00     0.0  0.00  0.00    \n",
       "10948  42.86     58.33  4.76        1.19       1.19     0.0  0.00  1.19    \n",
       "\n",
       "       L_shehe  L_they  L_ipron  L_article  L_prep  L_auxverb  L_adverb  \\\n",
       "10944  0.0      0.0     0.00     0.64       1.27    3.18       0.64       \n",
       "10945  0.0      0.0     0.81     0.81       1.61    0.81       1.61       \n",
       "10946  0.0      0.0     1.38     0.69       0.69    1.38       2.76       \n",
       "10947  0.0      0.0     0.00     0.00       1.32    0.66       0.00       \n",
       "10948  0.0      0.0     0.00     0.00       1.19    1.19       2.38       \n",
       "\n",
       "       L_conj  L_negate  L_verb  L_adj  L_compare  L_interrog  L_number  \\\n",
       "10944  0.00    0.64      12.74   8.28   1.91       0.0         1.27       \n",
       "10945  0.00    0.81      11.29   2.42   1.61       0.0         1.61       \n",
       "10946  0.69    3.45      8.97    1.38   0.69       0.0         3.45       \n",
       "10947  0.66    3.31      4.64    5.30   1.32       0.0         3.31       \n",
       "10948  0.00    0.00      11.90   3.57   1.19       0.0         0.00       \n",
       "\n",
       "       L_quant  L_affect  L_posemo  L_negemo  L_anx  L_anger  L_sad  L_social  \\\n",
       "10944  0.00     12.10     6.37      5.73      0.00   3.82     0.64   9.55       \n",
       "10945  0.81     11.29     7.26      4.03      1.61   1.61     0.00   14.52      \n",
       "10946  0.00     8.28      3.45      2.76      1.38   0.69     0.00   8.97       \n",
       "10947  2.65     2.65      1.99      0.66      0.66   0.00     0.00   11.92      \n",
       "10948  1.19     9.52      7.14      2.38      1.19   0.00     0.00   16.67      \n",
       "\n",
       "       L_family  L_friend  L_female  L_male  L_cogproc  L_insight  L_cause  \\\n",
       "10944  0.64      0.00      1.91      0.0     8.28       2.55       1.27      \n",
       "10945  0.00      0.00      0.00      0.0     8.06       2.42       2.42      \n",
       "10946  0.69      0.00      0.00      0.0     9.66       1.38       0.00      \n",
       "10947  0.00      0.00      0.00      0.0     5.96       1.99       1.32      \n",
       "10948  0.00      1.19      0.00      0.0     5.95       1.19       2.38      \n",
       "\n",
       "       L_discrep  L_tentat  L_certain  L_differ  L_percept  L_see  L_hear  \\\n",
       "10944  2.55       1.91      1.27       0.64      5.10       1.91   1.91     \n",
       "10945  0.81       1.61      0.81       0.81      4.03       0.00   4.03     \n",
       "10946  1.38       2.76      0.00       4.83      3.45       2.76   0.69     \n",
       "10947  1.32       0.66      0.66       0.66      3.31       1.32   1.99     \n",
       "10948  1.19       0.00      2.38       0.00      8.33       4.76   3.57     \n",
       "\n",
       "       L_feel  L_bio  L_body  L_health  L_sexual  L_ingest  L_drives  \\\n",
       "10944  1.27    2.55   0.64    1.27      0.64      0.64      15.92      \n",
       "10945  0.00    0.00   0.00    0.00      0.00      0.00      16.13      \n",
       "10946  0.00    1.38   0.69    0.00      0.00      0.69      18.62      \n",
       "10947  0.00    2.65   1.99    0.66      0.00      0.66      12.58      \n",
       "10948  0.00    4.76   0.00    4.76      0.00      0.00      11.90      \n",
       "\n",
       "       L_affiliation  L_achieve  L_power  L_reward  L_risk  L_focuspast  \\\n",
       "10944  3.82           2.55       8.28     0.64      1.27    3.18          \n",
       "10945  4.84           2.42       6.45     2.42      1.61    4.84          \n",
       "10946  4.83           2.76       11.03    0.69      0.00    1.38          \n",
       "10947  6.62           1.32       4.64     0.66      0.66    3.97          \n",
       "10948  7.14           0.00       2.38     1.19      1.19    5.95          \n",
       "\n",
       "       L_focuspresent  L_focusfuture  L_relativ  L_motion  L_space  L_time  \\\n",
       "10944  7.01            0.64           10.83      2.55      0.64     7.64     \n",
       "10945  6.45            0.00           16.13      4.03      6.45     4.84     \n",
       "10946  5.52            1.38           9.66       6.21      0.69     4.14     \n",
       "10947  1.32            0.00           14.57      1.99      6.62     4.64     \n",
       "10948  8.33            0.00           13.10      2.38      9.52     1.19     \n",
       "\n",
       "       L_work  L_leisure  L_home  L_money  L_relig  L_death  L_informal  \\\n",
       "10944  6.37    3.82       0.00    0.00     0.64     0.00     1.27         \n",
       "10945  12.90   4.03       0.00    0.81     0.00     1.61     3.23         \n",
       "10946  11.03   6.21       0.69    0.00     0.00     0.00     3.45         \n",
       "10947  9.27    6.62       0.66    1.32     0.00     0.00     1.99         \n",
       "10948  2.38    7.14       0.00    1.19     0.00     0.00     2.38         \n",
       "\n",
       "       L_swear  L_netspeak  L_assent  L_nonflu  L_filler  L_AllPunc  L_Period  \\\n",
       "10944  0.0      1.27        0.00      0.0       0.0       28.03      11.46      \n",
       "10945  0.0      1.61        1.61      0.0       0.0       31.45      10.48      \n",
       "10946  0.0      2.76        0.69      0.0       0.0       34.48      11.03      \n",
       "10947  0.0      1.32        0.66      0.0       0.0       33.77      10.60      \n",
       "10948  0.0      1.19        1.19      0.0       0.0       26.19      13.10      \n",
       "\n",
       "       L_Comma  L_Colon  L_SemiC  L_QMark  L_Exclam  L_Dash  L_Quote  \\\n",
       "10944  7.01     0.64     0.00     0.0      0.00      7.01    0.0       \n",
       "10945  4.84     3.23     0.00     0.0      0.81      9.68    0.0       \n",
       "10946  7.59     1.38     0.69     0.0      0.69      6.90    0.0       \n",
       "10947  6.62     2.65     0.00     0.0      0.66      11.26   0.0       \n",
       "10948  5.95     1.19     1.19     0.0      1.19      1.19    0.0       \n",
       "\n",
       "       L_Apostro  L_Parenth  L_OtherP  R_full_text_Flesch_reading_ease  \\\n",
       "10944  0          0.00       1.91      60.88                             \n",
       "10945  0          0.00       2.42      44.64                             \n",
       "10946  0          1.38       4.83      39.98                             \n",
       "10947  0          0.00       1.99      50.76                             \n",
       "10948  0          0.00       2.38      70.43                             \n",
       "\n",
       "       R_full_text_Flesch_kincaid_grade  R_full_text_smog  \\\n",
       "10944  13.5                              12.2               \n",
       "10945  15.6                              14.0               \n",
       "10946  17.4                              15.3               \n",
       "10947  16.2                              14.6               \n",
       "10948  13.3                              13.7               \n",
       "\n",
       "       R_full_text_gunning_fog  R_full_text_words_per_sentence  \\\n",
       "10944  20.067216                10.437500                        \n",
       "10945  19.450999                9.769231                         \n",
       "10946  18.884695                14.363636                        \n",
       "10947  20.333954                12.076923                        \n",
       "10948  19.337688                9.363636                         \n",
       "\n",
       "       R_full_text_capitalized_words  R_full_text_lexicon  \\\n",
       "10944  51                             140                   \n",
       "10945  30                             106                   \n",
       "10946  36                             125                   \n",
       "10947  37                             127                   \n",
       "10948  35                             83                    \n",
       "\n",
       "       R_full_text_urls_counts  R_full_text_long_words  R_full_text_syllables  \\\n",
       "10944  1                        109                     274                     \n",
       "10945  1                        83                      233                     \n",
       "10946  1                        95                      281                     \n",
       "10947  1                        96                      268                     \n",
       "10948  0                        60                      154                     \n",
       "\n",
       "       R_full_text_stop_words  R_full_text_sentences  \\\n",
       "10944  107.185629              16                      \n",
       "10945  140.944882              13                      \n",
       "10946  113.291139              11                      \n",
       "10947  114.012739              13                      \n",
       "10948  173.786408              11                      \n",
       "\n",
       "       R_full_text_linsear_write  R_full_text_automated_readability  \\\n",
       "10944  6.875000                   19.4                                \n",
       "10945  10.428571                  23.8                                \n",
       "10946  10.571429                  22.5                                \n",
       "10947  14.200000                  24.0                                \n",
       "10948  12.600000                  17.1                                \n",
       "\n",
       "       R_full_text_characters_total  R_full_text_coleman_liax  \\\n",
       "10944  1158                          21.92                      \n",
       "10945  986                           27.13                      \n",
       "10946  1071                          23.14                      \n",
       "10947  1121                          24.76                      \n",
       "10948  624                           18.15                      \n",
       "\n",
       "       R_full_text_difficult_words  R_full_text_words_total  T_totalTweets  \\\n",
       "10944  58                           167                      7               \n",
       "10945  43                           127                      5               \n",
       "10946  44                           158                      27              \n",
       "10947  53                           157                      9               \n",
       "10948  35                           103                      6               \n",
       "\n",
       "       T_totalRetweets  T_totalLikes  T_totalReplies       T_span  \\\n",
       "10944  13               13            1               16.766667     \n",
       "10945  12               11            2               6.716667      \n",
       "10946  62               58            9               1432.600000   \n",
       "10947  3                5             2               13.950000     \n",
       "10948  5                35            0               719.833333    \n",
       "\n",
       "       T_countWeekDay  T_countWeekEnd  T_countMonday  T_countTuesday  \\\n",
       "10944  7               0               0              0                \n",
       "10945  5               0               5              0                \n",
       "10946  13              14              1              0                \n",
       "10947  9               0               9              0                \n",
       "10948  6               0               4              0                \n",
       "\n",
       "       T_countWednesday  T_countThursday  T_countFriday  T_countSaturday  \\\n",
       "10944  0                 5                2              0                 \n",
       "10945  0                 0                0              0                 \n",
       "10946  0                 2                10             9                 \n",
       "10947  0                 0                0              0                 \n",
       "10948  2                 0                0              0                 \n",
       "\n",
       "       T_countSunday  T_avgTimeBetweenTweets  T_avgTimeOfNextTweet  \\\n",
       "10944  0              2.794444                3.580556               \n",
       "10945  0              1.679167                3.108333               \n",
       "10946  5              55.100000               85.323077              \n",
       "10947  0              1.743750                3.783333               \n",
       "10948  0              143.966667              284.386667             \n",
       "\n",
       "       T_timeAbsBin1count0to6  T_timeAbsBin2count6to12  \\\n",
       "10944  6                       0                         \n",
       "10945  4                       1                         \n",
       "10946  6                       3                         \n",
       "10947  7                       1                         \n",
       "10948  4                       0                         \n",
       "\n",
       "       T_timeAbsBin3count12to18  T_timeAbsBin4count18to24  \\\n",
       "10944  1                         0                          \n",
       "10945  0                         0                          \n",
       "10946  0                         2                          \n",
       "10947  1                         0                          \n",
       "10948  0                         0                          \n",
       "\n",
       "       T_timeAbsBin5count24plus  T_avgTweetsPerUniqUser  M_dollar  \\\n",
       "10944  0                         1.166667               -1          \n",
       "10945  0                         1.000000               -1          \n",
       "10946  16                        1.000000               -1          \n",
       "10947  0                         1.125000               -1          \n",
       "10948  2                         1.000000               -1          \n",
       "\n",
       "       M_dblApostrophe  M_comma  M_-LRB-  M_-RRB-  M_dot  M_colon  M_ADD  \\\n",
       "10944 -1                11      -1       -1        14     1        1       \n",
       "10945 -1                6       -1       -1        9      4        1       \n",
       "10946 -1                11       1        1        8      4       -1       \n",
       "10947 -1                9       -1       -1        10     4        1       \n",
       "10948 -1                5       -1       -1        10     2       -1       \n",
       "\n",
       "       M_AFX  M_CC  M_CD  M_DT  M_EX  M_FW  M_HYPH  M_IN  M_JJ  M_JJR  M_JJS  \\\n",
       "10944 -1     -1    -1    -1    -1    -1    -1      -1     15    1     -1       \n",
       "10945 -1     -1     2    -1    -1    -1     1      -1     9    -1     -1       \n",
       "10946 -1      1     5     1    -1     1     3      -1     4    -1     -1       \n",
       "10947 -1     -1     3     4    -1    -1     4       1     15   -1      1       \n",
       "10948 -1      1    -1    -1    -1    -1     1       1     3    -1      1       \n",
       "\n",
       "       M_LS  M_MD  M_NFP  M_NN  M_NNP  M_NNPS  M_NNS  M_PDT  M_POS  M_PRP  \\\n",
       "10944 -1     3    -1      23    47     1       16    -1     -1     -1       \n",
       "10945 -1    -1    -1      33    26    -1       7     -1     -1     -1       \n",
       "10946 -1     1     1      19    32     1       18    -1     -1     -1       \n",
       "10947 -1    -1    -1      35    32    -1       12    -1     -1     -1       \n",
       "10948 -1     1    -1      24    30     2       2     -1     -1      1       \n",
       "\n",
       "       M_PRP$  M_RB  M_RBR  M_RBS  M_RP  M_SYM  M_TO  M_UH  M_VB  M_VBD  \\\n",
       "10944 -1       4    -1     -1     -1    -1     -1    -1     4     8       \n",
       "10945 -1       3     1     -1     -1    -1     -1    -1     2     11      \n",
       "10946 -1       17   -1     -1     -1    -1     -1    -1     3     4       \n",
       "10947 -1       3    -1     -1     -1    -1     -1    -1     1     11      \n",
       "10948 -1       2    -1     -1     -1    -1     -1    -1     3     5       \n",
       "\n",
       "       M_VBG  M_VBN  M_VBP  M_VBZ  M_WDT  M_WP  M_WP$  M_WRB  M_XX  M__SP  \\\n",
       "10944  8      3      3      4     -1     -1    -1     -1     -1    -1       \n",
       "10945  7      1      2      2     -1     -1    -1     -1     -1    -1       \n",
       "10946  7      3      7      5     -1     -1    -1     -1     -1    -1       \n",
       "10947  2      2      4      3     -1     -1    -1     -1     -1    -1       \n",
       "10948  4      2      1      2     -1     -1    -1     -1     -1    -1       \n",
       "\n",
       "       M_dblSpecialApostrophe  \n",
       "10944 -1                       \n",
       "10945 -1                       \n",
       "10946 -1                       \n",
       "10947 -1                       \n",
       "10948 -1                       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reliable', 'Fake'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Features['urlType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['domain',\n",
       " 'url',\n",
       " 'urlType',\n",
       " 'L_WC',\n",
       " 'L_Analytic',\n",
       " 'L_Clout',\n",
       " 'L_Authentic',\n",
       " 'L_Tone',\n",
       " 'L_WPS',\n",
       " 'L_Sixltr',\n",
       " 'L_Dic',\n",
       " 'L_function',\n",
       " 'L_pronoun',\n",
       " 'L_ppron',\n",
       " 'L_i',\n",
       " 'L_we',\n",
       " 'L_you',\n",
       " 'L_shehe',\n",
       " 'L_they',\n",
       " 'L_ipron',\n",
       " 'L_article',\n",
       " 'L_prep',\n",
       " 'L_auxverb',\n",
       " 'L_adverb',\n",
       " 'L_conj',\n",
       " 'L_negate',\n",
       " 'L_verb',\n",
       " 'L_adj',\n",
       " 'L_compare',\n",
       " 'L_interrog',\n",
       " 'L_number',\n",
       " 'L_quant',\n",
       " 'L_affect',\n",
       " 'L_posemo',\n",
       " 'L_negemo',\n",
       " 'L_anx',\n",
       " 'L_anger',\n",
       " 'L_sad',\n",
       " 'L_social',\n",
       " 'L_family',\n",
       " 'L_friend',\n",
       " 'L_female',\n",
       " 'L_male',\n",
       " 'L_cogproc',\n",
       " 'L_insight',\n",
       " 'L_cause',\n",
       " 'L_discrep',\n",
       " 'L_tentat',\n",
       " 'L_certain',\n",
       " 'L_differ',\n",
       " 'L_percept',\n",
       " 'L_see',\n",
       " 'L_hear',\n",
       " 'L_feel',\n",
       " 'L_bio',\n",
       " 'L_body',\n",
       " 'L_health',\n",
       " 'L_sexual',\n",
       " 'L_ingest',\n",
       " 'L_drives',\n",
       " 'L_affiliation',\n",
       " 'L_achieve',\n",
       " 'L_power',\n",
       " 'L_reward',\n",
       " 'L_risk',\n",
       " 'L_focuspast',\n",
       " 'L_focuspresent',\n",
       " 'L_focusfuture',\n",
       " 'L_relativ',\n",
       " 'L_motion',\n",
       " 'L_space',\n",
       " 'L_time',\n",
       " 'L_work',\n",
       " 'L_leisure',\n",
       " 'L_home',\n",
       " 'L_money',\n",
       " 'L_relig',\n",
       " 'L_death',\n",
       " 'L_informal',\n",
       " 'L_swear',\n",
       " 'L_netspeak',\n",
       " 'L_assent',\n",
       " 'L_nonflu',\n",
       " 'L_filler',\n",
       " 'L_AllPunc',\n",
       " 'L_Period',\n",
       " 'L_Comma',\n",
       " 'L_Colon',\n",
       " 'L_SemiC',\n",
       " 'L_QMark',\n",
       " 'L_Exclam',\n",
       " 'L_Dash',\n",
       " 'L_Quote',\n",
       " 'L_Apostro',\n",
       " 'L_Parenth',\n",
       " 'L_OtherP',\n",
       " 'R_full_text_Flesch_reading_ease',\n",
       " 'R_full_text_Flesch_kincaid_grade',\n",
       " 'R_full_text_smog',\n",
       " 'R_full_text_gunning_fog',\n",
       " 'R_full_text_words_per_sentence',\n",
       " 'R_full_text_capitalized_words',\n",
       " 'R_full_text_lexicon',\n",
       " 'R_full_text_urls_counts',\n",
       " 'R_full_text_long_words',\n",
       " 'R_full_text_syllables',\n",
       " 'R_full_text_stop_words',\n",
       " 'R_full_text_sentences',\n",
       " 'R_full_text_linsear_write',\n",
       " 'R_full_text_automated_readability',\n",
       " 'R_full_text_characters_total',\n",
       " 'R_full_text_coleman_liax',\n",
       " 'R_full_text_difficult_words',\n",
       " 'R_full_text_words_total',\n",
       " 'T_totalTweets',\n",
       " 'T_totalRetweets',\n",
       " 'T_totalLikes',\n",
       " 'T_totalReplies',\n",
       " 'T_span',\n",
       " 'T_countWeekDay',\n",
       " 'T_countWeekEnd',\n",
       " 'T_countMonday',\n",
       " 'T_countTuesday',\n",
       " 'T_countWednesday',\n",
       " 'T_countThursday',\n",
       " 'T_countFriday',\n",
       " 'T_countSaturday',\n",
       " 'T_countSunday',\n",
       " 'T_avgTimeBetweenTweets',\n",
       " 'T_avgTimeOfNextTweet',\n",
       " 'T_timeAbsBin1count0to6',\n",
       " 'T_timeAbsBin2count6to12',\n",
       " 'T_timeAbsBin3count12to18',\n",
       " 'T_timeAbsBin4count18to24',\n",
       " 'T_timeAbsBin5count24plus',\n",
       " 'T_avgTweetsPerUniqUser',\n",
       " 'M_dollar',\n",
       " 'M_dblApostrophe',\n",
       " 'M_comma',\n",
       " 'M_-LRB-',\n",
       " 'M_-RRB-',\n",
       " 'M_dot',\n",
       " 'M_colon',\n",
       " 'M_ADD',\n",
       " 'M_AFX',\n",
       " 'M_CC',\n",
       " 'M_CD',\n",
       " 'M_DT',\n",
       " 'M_EX',\n",
       " 'M_FW',\n",
       " 'M_HYPH',\n",
       " 'M_IN',\n",
       " 'M_JJ',\n",
       " 'M_JJR',\n",
       " 'M_JJS',\n",
       " 'M_LS',\n",
       " 'M_MD',\n",
       " 'M_NFP',\n",
       " 'M_NN',\n",
       " 'M_NNP',\n",
       " 'M_NNPS',\n",
       " 'M_NNS',\n",
       " 'M_PDT',\n",
       " 'M_POS',\n",
       " 'M_PRP',\n",
       " 'M_PRP$',\n",
       " 'M_RB',\n",
       " 'M_RBR',\n",
       " 'M_RBS',\n",
       " 'M_RP',\n",
       " 'M_SYM',\n",
       " 'M_TO',\n",
       " 'M_UH',\n",
       " 'M_VB',\n",
       " 'M_VBD',\n",
       " 'M_VBG',\n",
       " 'M_VBN',\n",
       " 'M_VBP',\n",
       " 'M_VBZ',\n",
       " 'M_WDT',\n",
       " 'M_WP',\n",
       " 'M_WP$',\n",
       " 'M_WRB',\n",
       " 'M_XX',\n",
       " 'M__SP',\n",
       " 'M_dblSpecialApostrophe']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_Features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing of data to devide it into target and feature set\n",
    "X=all_Features.drop(columns=['url','domain','urlType'])\n",
    "y=all_Features['urlType'].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with criterion gini index [DT(G)] Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=100, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100)\n",
    "clf_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fake', 'Fake', 'Fake', ..., 'Reliable', 'Fake', 'Reliable'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_gi = clf_gini.predict(X_test)\n",
    "y_pred_gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[939 169]\n",
      " [162 920]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_gi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 84.88584474885845\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is {}\".format(accuracy_score(y_test,y_pred_gi)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree with criterion entropy index [DT(E)] Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=100, splitter='best')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100)\n",
    "clf_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reliable', 'Reliable', 'Fake', ..., 'Fake', 'Fake', 'Fake'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "y_pred_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[938 170]\n",
      " [185 897]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 83.78995433789954\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is {}\".format(accuracy_score(y_test,y_pred_en)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shekharsingh/anaconda3/envs/FakeNewsEnv1/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[829 279]\n",
      " [339 743]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 71.78082191780823\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy is {}\".format(accuracy_score(y_test,y_pred_knn)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (RF) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shekharsingh/anaconda3/envs/FakeNewsEnv1/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=100,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree = RandomForestClassifier(random_state=100, n_estimators=100)\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = model_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1026   82]\n",
      " [  94  988]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 91.9634703196347\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy is {}\".format(accuracy_score(y_test,y_pred_rf)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shekharsingh/anaconda3/envs/FakeNewsEnv1/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1006  102]\n",
      " [ 111  971]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 90.27397260273973\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy is {}\".format(accuracy_score(y_test,y_pred_svm)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (LR) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shekharsingh/anaconda3/envs/FakeNewsEnv1/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/shekharsingh/anaconda3/envs/FakeNewsEnv1/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shekharsingh/anaconda3/envs/FakeNewsEnv1/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[891 217]\n",
      " [225 857]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 79.81735159817352\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy is {}\".format(accuracy_score(y_test,y_pred_lr)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(learning_rate = 0.05, n_estimators = 300, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shekharsingh/anaconda3/envs/FakeNewsEnv1/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shekharsingh/anaconda3/envs/FakeNewsEnv1/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=300, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xg = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1049   59]\n",
      " [  74 1008]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 93.9269406392694\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy is {}\".format(accuracy_score(y_test,y_pred_xg)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
